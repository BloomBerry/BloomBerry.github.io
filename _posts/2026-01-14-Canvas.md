# [Agent] CANVAS: A Benchmark for Vision-Language Models on Tool-Based UI Design

- paper: https://arxiv.org/pdf/2511.20737
- github: X
- AAAI 2026 accepted (인용수: 0회, '26-01-14 기준)
- downstream task: Screenshot web 복원,  Screenshot web 편집

# 1. Motivation

- 기존에 UI Design benchmark는 code 기반 (HTML) 혹은 이미지 기반인데 비해, tool기반의 디자인 성능 측정하는 benchmark가 없었음

- 최근 VLM들은 agentic tool invocation 능력을 갖추었음

  $\to$ VLM의 tool-based 능력을 활용한 UI Design benchmark를 제안해보자!

  ![](../images/2026-01-06/image-20260114005242803.png)

# 2. Contribution

- VLM의 Tool기반 UI Generation 성능을 측정하는 최초의 benchmark인 CANVAS를 제안함

  ![](../images/2026-01-06/image-20260114005850212.png)

- 598개의 tool-driven design tasks로 구성 (총 3,327 UI로부터 취득)

  - Repliation: 주어진 이미지(Target Image)를 복원하는 task
  - Modification: 주어진 이미지(Base Image)에서 특정 query기반으로 편집을 수행하는 task

- 5개의 상용모델 기반으로 다각도로 평가를 진행함

  - Tool-use의 insight를 도출함 (정량적 & 정성적 평가)

# 3. Canvas (Benchmark Design)

## Task Design

Real-world를 반영한 테스크 구축이 목적

- Design replication: 주어진 Reference 이미지를 완성(복원)하는 태스크

- Design modification: 주어진 Base 이미지에서 명령 기반으로 편집을 수행하는 태스크

  ex. *"create a rectangle as a button background"*

-  Components (buttons, text)와 그 attributes의 value값이 쌍을 이루어 **state**로 정의

  ![](../images/2026-01-06/image-20260114011448642.png)

  - $c_i$: i번째 component
  - $a_{ij}$: i번째 component의 j번째 속성
  - $v$: $a_{ij}$속성의 값
  - $s$: 예측한 state. $s_{GT}$는 정답 state.

### Design Replication

- 빈 화면으로부터 제공된 $s_{GT}$를 도출하는 VLM의 tool invocation 능력을 평가

  ![](../images/2026-01-06/image-20260114011808613.png)

### Design Modification

- VLM이 정밀한 편집을 위한 tool invocation 능력을 평가

  ![](../images/2026-01-06/image-20260114012031881.png)

  - 속성 업데이트: 타켓 component *c*의 attribute *a*를 업데이트 (ex. color, size, text content, corner radius, position)

    ![](../images/2026-01-06/image-20260114012210193.png)

  - 속성 추가: 새로운 component-attribute pairs list를 추가하는 task

    ![](../images/2026-01-06/image-20260114012250958.png)

  - 모드 변경: color list를 새로운 attribute로 변경하는 task (마스터 프레젠테이션 느낌)

    ![](../images/2026-01-06/image-20260114012859398.png)

    ![](../images/2026-01-06/image-20260114012100831.png)

## Dataset Creation

### Data Source

- Figma Community로부터 UI design를 취득하고, designer review를 거침.
- CC-BY-4.0 License 인 템플릿만 대상으로 추출

### Data Collection

- Data Selection: 수동으로 선별하였으며
  - editable UI일 것 (non-editable UI는 제외 $\to$ ex. prototyping kits)
  - 추가적인 디자인이 minimal variation인 경우 멈춤
  - Figma의 REST API를 활용하여 SVG, PNG, Json을 추출
- Data Sampling
  - GPT-4.1 MINI를 통해 30개의 UI type로 분류됨
  - Replication set (n=298)은 stratified sampling을 통해 original pool(n=3,327)에서 추출
    - stratified sampling을 통해 모든 카테고리별로 10개씩 샘플링 (1개 카테고리만 8개)
  - Modification set(n=300)은 수동으로 샘플링 되었으며, task와 연관된 attribute을 기준으로 선별됨 (ex. round borders)
- Data Annotation
  - 속성 업데이트 & Component 추가 task는 base state와 target state를 주고 GPT-4.1 Mini를 기반으로 instructions를 생성함
  - 수동으로 원본 디자인을 수정하여 state 쌍을 구축함

### Data Refinement

- 

## Data Statistics

## Evaluation Metrics

# 4. Experiments