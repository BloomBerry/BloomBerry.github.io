---
title: "[SSDA][CLS] MARRS: Modern Backbones Assisted Co-training for Rapid and Robust Semi-Supervised Domain Adaptation"
---
# [SSDA][CLS] MARRS: Modern Backbones Assisted Co-training for Rapid and Robust Semi-Supervised Domain Adaptation

- paper : https://openaccess.thecvf.com/content/CVPR2023W/ECV/papers/Jain_MARRS_Modern_Backbones_Assisted_Co-Training_for_Rapid_and_Robust_Semi-Supervised_CVPRW_2023_paper.pdf

- CVPRW 2023 accepted (인용수: 0회, '23.10.30기준)

- downsteram task : SSDA for Classification

- Motivation

  - SSDA for classification에 사용되던 baseline 모델 (Res-34)이 out-dated임
  - 단순한 SSL기법 적용한 최신 모델을 활용해서 (CovNext-L) baseline모델 상회

- Contribution

  - SSDA task에 최신 CNN, Vistion-Transformer 모델을 활용한 Co-training 기반 backbone으로 교체 적용

  - Diverse feature 학습을 위해 3가지 모듈 적용 (image-level, feature-level, backbone-level)

    ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-40-10.png)

  - SSDA Datazset SOTA 달성

  - KD 활용한 Mbv2 모델로도 SSDA Dataset SOTA달성

- Overview

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-40-44.png)

## Feature Extraction

- Backbone level diversity Module (BD)
  - CNN based : ConvNext-XL 
  - Vistion-Transformer based : Swin-L
- Image level diversity Module (ID)
  - training 시 weak-aug (psi)를 한쪽 모델에 주입
- Feature distribution level diversity Module (FD)
  - CORAL 을 한쪽 모델 출력에 연결

## Classifier Training

![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-41-56.png)

- 각 backbone의 confidence prediction을 pseudo-gt로 활용해서 학습 → Co-Training

- Loss

  - Supervised Loss : Labeled source db + Labeled target db (CE Loss)

    ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-42-42.png)

    - n : D dataset에 속한 sample 갯수
    - K : Class 갯수
    - F : classifier F의 출력
    - Label smoothing을 통해 source에 over-confidence 방지

  - Unsupervised Loss

    ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-43-02.png)

    - Unlabeled target db (CELoss) : Co-training 
    - Consistency regularization Loss : Strong-aug feature와 original feature간의 일치하도록 강제
      - Strong Aug = RandAugment 사용

- KD 

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-43-43.png)

  - Inference 속도 향상을 위해 적용
    - Teacher : Swin-L + CovNext-XL (MARRS)
    - Student : MobileNet-V2

- Algorithm

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-44-02.png)

- Experiment

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-44-36.png)

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-44-21.png)

- Ablation Studies

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-44-55.png)

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-45-07.png)

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-45-24.png)

- Inference Time

  ![](../images/2024-01-11/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-01-11%2022-45-39.png)
