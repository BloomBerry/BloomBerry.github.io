---
title: "[MM] MMICL: EMPOWERING VISION-LANGUAGE MODEL WITH MULTI-MODAL IN-CONTEXT LEARNING"
---
# [MM] MMICL: EMPOWERING VISION-LANGUAGE MODEL WITH MULTI-MODAL IN-CONTEXT LEARNING

- paper: https://arxiv.org/pdf/2309.07915
- github: https://github.com/PKUnlp-icler/MIC
- ICLR 2024 accepted (인용수: 10회, '24-06-27)
- downstream task: MME , VL reasoning, zero-shot VQA ,etc

# 1. Motivation

# 2. Contribution

# 3. MMICL

# 4. Experiments

